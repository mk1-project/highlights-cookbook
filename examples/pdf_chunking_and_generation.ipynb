{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Processing with Highlights and OpenAI Integration\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Convert a PDF document to text\n",
    "2. Split the text into page-level chunks\n",
    "3. Use Highlights API to search for relevant chunks\n",
    "4. Send the most relevant chunks to OpenAI for text generation\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 openai python-dotenv\n",
    "\n",
    "import os\n",
    "import PyPDF2\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "from base_client import HighlightsClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Environment Variables\n",
    "\n",
    "Create a .env file with your API keys:\n",
    "```\n",
    "HIGHLIGHTS_API_KEY=your-highlights-api-key\n",
    "OPENAI_API_KEY=your-openai-api-key\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize clients\n",
    "highlights_client = HighlightsClient(api_key=os.getenv('HIGHLIGHTS_API_KEY'))\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Processing Class\n",
    "\n",
    "Let's create a class to handle our PDF processing workflow. Our simple implementation will extract text from a PDF, split it into chunks based on pages, which will thereafter be fed into the Highlights API to search for relevant chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFProcessor:\n",
    "    def __init__(self, highlights_client, temperature: float = 0.7):\n",
    "        self.highlights_client = highlights_client\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract text from PDF, split by pages.\n",
    "\n",
    "        Args:\n",
    "            pdf_path: Path to the PDF file\n",
    "\n",
    "        Returns:\n",
    "            List of strings, where each string is the text from one page\n",
    "        \"\"\"\n",
    "        text_chunks = []\n",
    "\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            # Create PDF reader object\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "            # Extract text from each page\n",
    "            for page in pdf_reader.pages:\n",
    "                text = page.extract_text()\n",
    "                if text.strip():  # Only add non-empty pages\n",
    "                    text_chunks.append(text)\n",
    "\n",
    "        return text_chunks\n",
    "\n",
    "    def search_relevant_chunks(self, query: str, text_chunks: List[str], top_n: int = 3) -> List[str]:\n",
    "        \"\"\"\n",
    "        Search for relevant chunks using Highlights API.\n",
    "\n",
    "        Args:\n",
    "            query: Search query\n",
    "            text_chunks: List of text chunks to search through\n",
    "            top_n: Number of top results to return\n",
    "\n",
    "        Returns:\n",
    "            List of most relevant text chunks\n",
    "        \"\"\"\n",
    "        results = self.highlights_client.search_text_chunks(\n",
    "            query=query,\n",
    "            text_chunks=text_chunks,\n",
    "            top_n=top_n\n",
    "        )\n",
    "\n",
    "        return [result['chunk_txt'] for result in results['results']]\n",
    "\n",
    "    def generate_response(self, query: str, context: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        Generate response using OpenAI API with context.\n",
    "\n",
    "        Args:\n",
    "            query: The question to answer\n",
    "            context: List of relevant text chunks to use as context\n",
    "\n",
    "        Returns:\n",
    "            Generated response\n",
    "        \"\"\"\n",
    "        # Combine context and prompt\n",
    "        combined_prompt = f\"\"\"\n",
    "        Context information is below.\n",
    "        ----------------\n",
    "        {' '.join(context)}\n",
    "        ----------------\n",
    "        Using the above context, please answer the following question: {query}\n",
    "        \"\"\"\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  # or another appropriate model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on provided context.\"},\n",
    "                {\"role\": \"user\", \"content\": combined_prompt}\n",
    "            ],\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the PDF Processor\n",
    "\n",
    "Now let's try processing a PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor\n",
    "processor = PDFProcessor(highlights_client)\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_path = 'data/border_act.pdf'\n",
    "\n",
    "# Extract text chunks from PDF\n",
    "text_chunks = processor.extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(f\"Extracted {len(text_chunks)} pages from PDF\")\n",
    "print(\"\\nSample from first page:\")\n",
    "print(text_chunks[0][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching and Generating\n",
    "\n",
    "Let's search for relevant chunks and generate a response based on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Am I an eligible individual for CONDITIONAL PERMANENT RESIDENT STATUS? I was paroled into the us in 2020.\"\n",
    "\n",
    "# Search for relevant chunks\n",
    "relevant_chunks = processor.search_relevant_chunks(\n",
    "    query=query,\n",
    "    text_chunks=text_chunks,\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "print(f\"Found {len(relevant_chunks)} relevant chunks\")\n",
    "# Generate response using OpenAI\n",
    "response = processor.generate_response(\n",
    "    query=query,\n",
    "    context=relevant_chunks\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Response:\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
