{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Processing with Highlights and OpenAI Integration\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Convert a PDF document to text\n",
    "2. Split the text into page-level chunks\n",
    "3. Use Highlights API to search for relevant chunks\n",
    "4. Send the most relevant chunks to OpenAI for text generation\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in /home/ysingh/.local/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: openai in /home/ysingh/.local/lib/python3.10/site-packages (1.63.2)\n",
      "Requirement already satisfied: python-dotenv in /home/ysingh/.local/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ysingh/.local/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ysingh/.local/lib/python3.10/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ysingh/.local/lib/python3.10/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ysingh/.local/lib/python3.10/site-packages (from openai) (1.10.18)\n",
      "Requirement already satisfied: sniffio in /home/ysingh/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/ysingh/.local/lib/python3.10/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ysingh/.local/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ysingh/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ysingh/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ysingh/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2 openai python-dotenv\n",
    "\n",
    "import os\n",
    "import PyPDF2\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "from base_client import HighlightsClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Environment Variables\n",
    "\n",
    "Create a .env file with your API keys:\n",
    "```\n",
    "HIGHLIGHTS_API_KEY=your-highlights-api-key\n",
    "OPENAI_API_KEY=your-openai-api-key\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize clients\n",
    "highlights_client = HighlightsClient(api_key=os.getenv('HIGHLIGHTS_API_KEY'))\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Processing Class\n",
    "\n",
    "Let's create a class to handle our PDF processing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFProcessor:\n",
    "    def __init__(self, highlights_client, temperature: float = 0.7):\n",
    "        self.highlights_client = highlights_client\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract text from PDF, split by pages.\n",
    "\n",
    "        Args:\n",
    "            pdf_path: Path to the PDF file\n",
    "\n",
    "        Returns:\n",
    "            List of strings, where each string is the text from one page\n",
    "        \"\"\"\n",
    "        text_chunks = []\n",
    "\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            # Create PDF reader object\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "            # Extract text from each page\n",
    "            for page in pdf_reader.pages:\n",
    "                text = page.extract_text()\n",
    "                if text.strip():  # Only add non-empty pages\n",
    "                    text_chunks.append(text)\n",
    "\n",
    "        return text_chunks\n",
    "\n",
    "    def search_relevant_chunks(self, query: str, text_chunks: List[str], top_n: int = 3) -> List[str]:\n",
    "        \"\"\"\n",
    "        Search for relevant chunks using Highlights API.\n",
    "\n",
    "        Args:\n",
    "            query: Search query\n",
    "            text_chunks: List of text chunks to search through\n",
    "            top_n: Number of top results to return\n",
    "\n",
    "        Returns:\n",
    "            List of most relevant text chunks\n",
    "        \"\"\"\n",
    "        results = self.highlights_client.search_text_chunks(\n",
    "            query=query,\n",
    "            text_chunks=text_chunks,\n",
    "            top_n=top_n\n",
    "        )\n",
    "\n",
    "        return [result['chunk_txt'] for result in results['results']]\n",
    "\n",
    "    def generate_response(self, query: str, context: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        Generate response using OpenAI API with context.\n",
    "\n",
    "        Args:\n",
    "            query: The question to answer\n",
    "            context: List of relevant text chunks to use as context\n",
    "\n",
    "        Returns:\n",
    "            Generated response\n",
    "        \"\"\"\n",
    "        # Combine context and prompt\n",
    "        combined_prompt = f\"\"\"\n",
    "        Context information is below.\n",
    "        ----------------\n",
    "        {' '.join(context)}\n",
    "        ----------------\n",
    "        Using the above context, please answer the following question: {query}\n",
    "        \"\"\"\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  # or another appropriate model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on provided context.\"},\n",
    "                {\"role\": \"user\", \"content\": combined_prompt}\n",
    "            ],\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the PDF Processor\n",
    "\n",
    "Now let's try processing a PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 292 pages from PDF\n",
      "\n",
      "Sample from first page:\n",
      "II \n",
      "Calendar No. 397 \n",
      "118 THCONGRESS \n",
      "2DSESSION  S. 4361 \n",
      "Making emergency supplemental appropriations for border security and com-\n",
      "batting fentanyl for the fiscal year ending September 30, 2024, and ...\n"
     ]
    }
   ],
   "source": [
    "# Initialize processor\n",
    "processor = PDFProcessor(highlights_client)\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_path = 'data/border_act.pdf'\n",
    "\n",
    "# Extract text chunks from PDF\n",
    "text_chunks = processor.extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(f\"Extracted {len(text_chunks)} pages from PDF\")\n",
    "print(\"\\nSample from first page:\")\n",
    "print(text_chunks[0][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching and Generating\n",
    "\n",
    "Let's search for relevant chunks and generate a response based on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 relevant chunks\n",
      "\n",
      "Generated Response:\n",
      "Based on the provided context, to be considered an \"eligible individual\" for CONDITIONAL PERMANENT RESIDENT STATUS under the specified law, you must meet the following criteria:\n",
      "\n",
      "1. Be present in the United States.\n",
      "2. Be a citizen or national of Afghanistan, or a person who last habitually resided in Afghanistan (if you have no nationality).\n",
      "3. Not have been granted permanent resident status.\n",
      "4. Have been inspected and admitted to the United States on or before the date of the enactment of the Act, or paroled into the United States during the specified period (from July 30, 2021, to the date of enactment), provided that such parole has not been terminated by the Secretary upon written notice.\n",
      "5. Be admissible to the United States as an immigrant under immigration laws.\n",
      "\n",
      "Since you stated that you were paroled into the U.S. in 2020, you would not qualify under the criteria regarding the specified parole period (which starts from July 30, 2021). Therefore, based on this information, you would **not** be considered an eligible individual for CONDITIONAL PERMANENT RESIDENT STATUS as described in the context.\n"
     ]
    }
   ],
   "source": [
    "query = \"Am I an eligible individual for CONDITIONAL PERMANENT RESIDENT STATUS? I was paroled into the us in 2020.\"\n",
    "\n",
    "# Search for relevant chunks\n",
    "relevant_chunks = processor.search_relevant_chunks(\n",
    "    query=query,\n",
    "    text_chunks=text_chunks,\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "print(f\"Found {len(relevant_chunks)} relevant chunks\")\n",
    "# Generate response using OpenAI\n",
    "response = processor.generate_response(\n",
    "    query=query,\n",
    "    context=relevant_chunks\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Response:\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
