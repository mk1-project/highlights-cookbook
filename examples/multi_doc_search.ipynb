{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Document Search and Question Answering with Highlights and OpenAI Integration\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Prepare documents for search\n",
    "3. Use Highlights API to search for relevant chunks\n",
    "4. Send the most relevant chunks to OpenAI for text generation\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/rdoshi/.venv/lib/python3.10/site-packages (1.65.0)\n",
      "Requirement already satisfied: python-dotenv in /home/rdoshi/.venv/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: datasets in /home/rdoshi/.venv/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: langchain_text_splitters in /home/rdoshi/.venv/lib/python3.10/site-packages (0.3.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /home/rdoshi/.venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/rdoshi/.venv/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/rdoshi/.venv/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: packaging in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/rdoshi/.venv/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /home/rdoshi/.venv/lib/python3.10/site-packages (from langchain_text_splitters) (0.3.40)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/rdoshi/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/rdoshi/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/rdoshi/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/rdoshi/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/rdoshi/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: certifi in /home/rdoshi/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/rdoshi/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/rdoshi/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/rdoshi/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_text_splitters) (0.3.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_text_splitters) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/rdoshi/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_text_splitters) (1.33)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/rdoshi/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rdoshi/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rdoshi/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/rdoshi/.venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/rdoshi/.venv/lib/python3.10/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/rdoshi/.venv/lib/python3.10/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/rdoshi/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_text_splitters) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/rdoshi/.venv/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_text_splitters) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_text_splitters) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/rdoshi/.venv/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_text_splitters) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/rdoshi/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai python-dotenv datasets langchain_text_splitters\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "from base_client import HighlightsClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Environment Variables\n",
    "\n",
    "Create a .env file with your API keys:\n",
    "```\n",
    "HIGHLIGHTS_API_KEY=your-highlights-api-key\n",
    "OPENAI_API_KEY=your-openai-api-key\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize clients\n",
    "highlights_client = HighlightsClient(api_key=os.getenv('HIGHLIGHTS_API_KEY'))\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Textbooks for Search\n",
    "\n",
    "First, let's download a some horticulture textbook chapters from the princeton-nlp dataset on Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 chapters from textbooks by Suza and Lamkey\n",
      "Split 26 chapters into 118 chunks\n"
     ]
    }
   ],
   "source": [
    "# Initialize processor and load dataset\n",
    "from datasets import load_dataset\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Extract textbooks from specific authors\n",
    "ds = load_dataset(\"princeton-nlp/TextbookChapters\")\n",
    "documents = {\n",
    "    item['path']: item['chapter']\n",
    "    for item in ds['train']\n",
    "    if \"Suza_and_Lamkey\" in item['path']\n",
    "}\n",
    "\n",
    "# Print summary of loaded documents\n",
    "print(f\"Loaded {len(documents)} chapters from textbooks by Suza and Lamkey\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets split the chapters into manageable chunks with helpful metadata. It's recommended to keep chunks between 1000 and 10000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 26 chapters into 118 chunks\n"
     ]
    }
   ],
   "source": [
    "# Define an xml-style template for each chunk with text and metadata\n",
    "text_chunk_template = \"\"\"\n",
    "<document>\n",
    "    <metadata>\n",
    "        <name>{document_name}</name>\n",
    "        <chunk_id>{document_chunk_id}</chunk_id>\n",
    "    </metadata>\n",
    "    <content>{chapter_text}</content>\n",
    "</document>\n",
    "\"\"\"\n",
    "\n",
    "# Use langchain's recursive text splitter to split the chapters into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=8192, chunk_overlap=0, separators=[\"\\n\\n\", \"\\n\", \". \"])\n",
    "\n",
    "text_chunks = []\n",
    "for path, chapter in documents.items():\n",
    "    chunks = text_splitter.split_text(chapter)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        document_text_chunk = text_chunk_template.format(document_name=path, chapter_text=chunk, document_chunk_id=i)\n",
    "        text_chunks.append(document_text_chunk)\n",
    "\n",
    "print(f\"Split {len(documents)} chapters into {len(text_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing Highlights to retrieve relevant chunks\n",
    "\n",
    "Let's search for relevant chunks given the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the different ways in which mutations can be classified?\"\n",
    "\n",
    "# Search for relevant chunks\n",
    "highlights_response = highlights_client.search_text_chunks(\n",
    "    query=query,\n",
    "    text_chunks=text_chunks,\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "relevent_passages = [result['chunk_txt'] for result in highlights_response['results']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenAI with Highlights response\n",
    "Highlights returns the original chunks that we passed in so forwarding those into OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response:\n",
      "Mutations can be classified in several ways, including:\n",
      "\n",
      "1. **Causal Agent**: \n",
      "   - **Spontaneous Mutations**: Occur naturally without intentional exposure to a mutagen, often due to errors during DNA replication.\n",
      "   - **Induced Mutations**: Caused by external factors, such as chemicals or radiation.\n",
      "\n",
      "2. **Rate or Frequency of Occurrence**:\n",
      "   - **Rare Mutations**: Occur infrequently in populations, typically recessive and often not observable in phenotypes.\n",
      "   - **Recurrent Mutations**: Occur repeatedly in populations and can influence gene frequency.\n",
      "\n",
      "3. **Kind of Tissue Involved and Type of Inheritance**:\n",
      "   - **Somatic Mutations**: Occur in somatic (non-reproductive) tissues and are not passed to offspring.\n",
      "   - **Germinal (Germ-Line) Mutations**: Occur in reproductive cells and can be inherited by future generations.\n",
      "\n",
      "4. **Impact on Fitness or Function**:\n",
      "   - **Deleterious Mutations**: Harmful and decrease the fitness of the individual.\n",
      "   - **Advantageous Mutations**: Beneficial and increase the fitness of the individual.\n",
      "   - **Neutral Mutations**: Have no significant effect on fitness.\n",
      "   - **Lethal Mutations**: Cause death of the organism when present.\n",
      "\n",
      "5. **Molecular Structure and Scale of the Mutation**:\n",
      "   - **Point Mutations**: Involve small changes such as substitutions, insertions, or deletions of one or a few nucleotide pairs.\n",
      "   - **Chromosomal Mutations**: Affect the structure or number of chromosomes, including deletions, duplications, inversions, translocations, etc.\n",
      "\n",
      "Each of these classifications highlights different aspects of mutations and their effects on genetic variation and evolution.\n"
     ]
    }
   ],
   "source": [
    "# Generate response using OpenAI\n",
    "context = '\\n\\n'.join(relevent_passages)\n",
    "combined_prompt = f\"\"\"\n",
    "Context information is below.\n",
    "----------------\n",
    "{context}\n",
    "----------------\n",
    "Using the above context, please answer the following question: {query}\n",
    "\"\"\"\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # or another appropriate model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on provided context.\"},\n",
    "        {\"role\": \"user\", \"content\": combined_prompt}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nGenerated Response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
