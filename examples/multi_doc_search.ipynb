{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Document Search and Question Answering with Highlights and OpenAI Integration\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Prepare documents for search\n",
    "3. Use Highlights API to search for relevant chunks\n",
    "4. Send the most relevant chunks to OpenAI for text generation\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai python-dotenv datasets langchain_text_splitters\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "from base_client import HighlightsClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Environment Variables\n",
    "\n",
    "Create a .env file with your API keys:\n",
    "```\n",
    "HIGHLIGHTS_API_KEY=your-highlights-api-key\n",
    "OPENAI_API_KEY=your-openai-api-key\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize clients\n",
    "highlights_client = HighlightsClient(api_key=os.getenv('HIGHLIGHTS_API_KEY'))\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Textbooks for Search\n",
    "\n",
    "First, let's download a some horticulture textbook chapters from the princeton-nlp dataset on Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor and load dataset\n",
    "from datasets import load_dataset\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Extract textbooks from specific authors\n",
    "ds = load_dataset(\"princeton-nlp/TextbookChapters\")\n",
    "documents = {\n",
    "    item['path']: item['chapter']\n",
    "    for item in ds['train']\n",
    "    if \"Suza_and_Lamkey\" in item['path']\n",
    "}\n",
    "\n",
    "# Print summary of loaded documents\n",
    "print(f\"Loaded {len(documents)} chapters from textbooks by Suza and Lamkey\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets split the chapters into manageable chunks with helpful metadata. It's recommended to keep chunks between 1000 and 10000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an xml-style template for each chunk with text and metadata\n",
    "text_chunk_template = \"\"\"\n",
    "<document>\n",
    "    <metadata>\n",
    "        <name>{document_name}</name>\n",
    "        <chunk_id>{document_chunk_id}</chunk_id>\n",
    "    </metadata>\n",
    "    <content>{chapter_text}</content>\n",
    "</document>\n",
    "\"\"\"\n",
    "\n",
    "# Use langchain's recursive text splitter to split the chapters into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=8192, chunk_overlap=0, separators=[\"\\n\\n\", \"\\n\", \". \"])\n",
    "\n",
    "text_chunks = []\n",
    "for path, chapter in documents.items():\n",
    "    chunks = text_splitter.split_text(chapter)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        document_text_chunk = text_chunk_template.format(document_name=path, chapter_text=chunk, document_chunk_id=i)\n",
    "        text_chunks.append(document_text_chunk)\n",
    "\n",
    "print(f\"Split {len(documents)} chapters into {len(text_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing Highlights to retrieve relevant chunks\n",
    "\n",
    "Let's search for relevant chunks given the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the different ways in which mutations can be classified?\"\n",
    "\n",
    "# Search for relevant chunks\n",
    "highlights_response = highlights_client.search_text_chunks(\n",
    "    query=query,\n",
    "    text_chunks=text_chunks,\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "relevent_passages = [result['chunk_txt'] for result in highlights_response['results']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenAI with Highlights response\n",
    "Highlights returns the original chunks that we passed in so forwarding those into OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate response using OpenAI\n",
    "context = '\\n\\n'.join(relevent_passages)\n",
    "combined_prompt = f\"\"\"\n",
    "Context information is below.\n",
    "----------------\n",
    "{context}\n",
    "----------------\n",
    "Using the above context, please answer the following question: {query}\n",
    "\"\"\"\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # or another appropriate model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on provided context.\"},\n",
    "        {\"role\": \"user\", \"content\": combined_prompt}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nGenerated Response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
