{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Search for Large Single Document wit Highlights\n",
    "\n",
    "This notebook demonstrates a streamlined approach to document question-answering using Highlights:\n",
    "\n",
    "1. **Efficiency**: Processes large documents without sending the entire content to a frontier LLM\n",
    "2. **Precision**: Uses Highlights' contextual awareness to identify relevant passages\n",
    "3. **Cost-effectiveness**: Reduces token usage by focusing only on relevant sections\n",
    "\n",
    "The implementation follows these steps:\n",
    "1. Convert a PDF document to text\n",
    "2. Split the text into page-level chunks\n",
    "3. Use Highlights API to retrieve contextually relevant chunks\n",
    "4. Send only the most relevant chunks to OpenAI for response generation\n",
    "\n",
    "## Setup\n",
    "\n",
    "Install the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 openai python-dotenv\n",
    "\n",
    "import os\n",
    "import PyPDF2\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "from base_client import HighlightsClient\n",
    "from utils import PDFProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Environment Variables\n",
    "\n",
    "Create a .env file with your API keys:\n",
    "```\n",
    "HIGHLIGHTS_API_KEY=your-highlights-api-key\n",
    "OPENAI_API_KEY=your-openai-api-key\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize clients\n",
    "highlights_client = HighlightsClient(api_key=os.getenv('HIGHLIGHTS_API_KEY'))\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Processing\n",
    "\n",
    "Extracting text from PDF documents presents several challenges including preserving formatting and structure. The PDFProcessor class handles this complexity while maintaining appropriate chunk boundaries for optimal retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 292 pages from PDF\n",
      "\n",
      "Sample from first page:\n",
      "II \n",
      "Calendar No. 397 \n",
      "118 THCONGRESS \n",
      "2DSESSION  S. 4361 \n",
      "Making emergency supplemental appropriations for border security and com-\n",
      "batting fentanyl for the fiscal year ending September 30, 2024, and ...\n"
     ]
    }
   ],
   "source": [
    "# Initialize processor\n",
    "processor = PDFProcessor(highlights_client)\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_path = 'data/border_act.pdf'\n",
    "\n",
    "# Extract text chunks from PDF\n",
    "text_chunks = processor.extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(f\"Extracted {len(text_chunks)} pages from PDF\")\n",
    "print(\"\\nSample from first page:\")\n",
    "print(text_chunks[0][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual Retrieval with Highlights\n",
    "\n",
    "Unlike vector search that treats chunks in isolation, Highlights evaluates each segment within its surrounding context, significantly improving retrieval relevance for large, complex documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 relevant chunks\n"
     ]
    }
   ],
   "source": [
    "query = \"Am I an eligible individual for CONDITIONAL PERMANENT RESIDENT STATUS? I was paroled into the us in 2020.\"\n",
    "\n",
    "# Search for relevant chunks\n",
    "relevant_chunks = processor.search_relevant_chunks(\n",
    "    query=query,\n",
    "    text_chunks=text_chunks,\n",
    "    top_n=5  # Limiting to top 5 chunks balances completeness with token efficiency\n",
    ")\n",
    "\n",
    "print(f\"Found {len(relevant_chunks)} relevant chunks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Generation\n",
    "\n",
    "By forwarding only the most relevant chunks to a frontier model, we achieve two key benefits:\n",
    "1. Reduced token consumption and lower costs\n",
    "2. Higher quality responses by eliminating distracting or irrelevant content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response:\n",
      "Based on the context provided, to be considered an \"eligible individual
